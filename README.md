

# ğŸ¤– Robot Server

[![Python](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111+-green)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Servidor en **FastAPI** para controlar y monitorear un robot hexÃ¡podo (**HexaMind**).
Optimizado para ejecutarse tanto en **PCs de desarrollo** como en **Jetson Nano** (edge computing).

Incluye:

* Control de movimiento del robot.
* Streaming de cÃ¡mara en tiempo real (MJPEG).
* DetecciÃ³n de colores en HSV.
* Reconocimiento facial.
* Sistema de eventos/alertas mediante bus interno.

---

## ğŸ“‘ Ãndice

1. [Arquitectura](#arquitectura)
2. [Requisitos](#requisitos)
3. [InstalaciÃ³n](#instalaciÃ³n)
4. [Uso](#uso)
5. [ConfiguraciÃ³n](#configuraciÃ³n)
6. [Estructura del Proyecto](#estructura-del-proyecto)
7. [Endpoints](#endpoints)

   * [7.1. BÃ¡sicos](#71-bÃ¡sicos)
   * [7.2. Movimiento](#72-movimiento)
   * [7.3. Endpoint `/move`](#73-endpoint-move)
8.  [WebSocket API](#websocket-api)
9.  [Testing](#testing)
10. [ContribuciÃ³n](#contribuciÃ³n)
11. [Roadmap](#roadmap)
12. [Licencia](#licencia)

---

## ğŸ—ï¸ Arquitectura

* **Lenguaje:** Python 3.11+
* **Framework:** FastAPI (ASGI, alto rendimiento)
* **IA:** OpenCV + Mediapipe (detecciÃ³n de colores y rostros)
* **Streaming:** MJPEG
* **Dispositivos target:**

  * Jetson Nano (edge)
  * Windows/Linux dev machines
* **PatrÃ³n:** Modular (IA, sensores, movimiento, core)

---

## ğŸ“‹ Requisitos

* Python **3.9+**
* `pip` actualizado
* CÃ¡mara compatible con OpenCV
* Jetson Nano (opcional, para despliegue embebido)

---

## âš™ï¸ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/usuario/robot-server.git
cd robot-server
```

### 2. Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Instalar dependencias

Dependencias base:

```bash
pip install -r requirements.base.txt
```

Si usas **Jetson Nano**:

```bash
pip install -r requirements.jetson.txt
```

En **Windows**:

```bash
pip install -r requirements.win.txt
```

---

## â–¶ï¸ Uso

### Linux / Mac

```bash
./run.sh
```

### Windows

```powershell
./run_dev.ps1
```

Servidor disponible en:
ğŸ‘‰ `http://localhost:8000`

Swagger UI (documentaciÃ³n automÃ¡tica):
ğŸ‘‰ `http://localhost:8000/docs`

---

## ğŸ”§ ConfiguraciÃ³n

Variables de entorno (`.env`):

| Variable         | DescripciÃ³n                  | Default   |
| ---------------- | ---------------------------- | --------- |
| `HOST`           | DirecciÃ³n de escucha         | `0.0.0.0` |
| `PORT`           | Puerto del servidor          | `8000`    |
| `CAMERA_INDEX`   | Ãndice de cÃ¡mara para OpenCV | `0`       |
| `STREAM_QUALITY` | Calidad MJPEG (1-100)        | `80`      |

---

## ğŸ“‚ Estructura del Proyecto

```bash
robot-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # Punto de entrada FastAPI
â”‚   â”œâ”€â”€ schemas.py            # Modelos de datos (Pydantic)
â”‚   â”œâ”€â”€ streaming.py          # Generador de stream MJPEG
â”‚   â”œâ”€â”€ core/                 # ConfiguraciÃ³n y bus de eventos
â”‚   â”‚   â”œâ”€â”€ alerts.py
â”‚   â”‚   â”œâ”€â”€ bus.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ IA/                   # MÃ³dulos de Inteligencia Artificial
â”‚   â”‚   â”œâ”€â”€ color_recognition.py
â”‚   â”‚   â”œâ”€â”€ face_recognition.py
â”‚   â”œâ”€â”€ motion/               # Control de movimiento del robot
â”‚   â”‚   â””â”€â”€ controller_vel.py
â”‚   â””â”€â”€ sensors/              # MÃ³dulos de sensores
â”‚       â””â”€â”€ camera.py
â”œâ”€â”€ requirements.base.txt
â”œâ”€â”€ requirements.jetson.txt
â”œâ”€â”€ requirements.win.txt
â”œâ”€â”€ run.sh
â””â”€â”€ run_dev.ps1
```

---

## ğŸ”Œ Endpoints

### 7.1. BÃ¡sicos

| MÃ©todo | Endpoint        | DescripciÃ³n                 |
| ------ | --------------- | --------------------------- |
| GET    | `/health`       | Estado del servidor         |
| GET    | `/stream.mjpg`  | Streaming de cÃ¡mara MJPEG   |
| GET    | `/snapshot.jpg` | Captura de imagen actual    |
| POST   | `/move`         | Comandos de movimiento JSON |

---

### 7.2. Movimiento

| MÃ©todo | Ruta         | DescripciÃ³n                           |
| ------ | ------------ | ------------------------------------- |
| POST   | `/vel`       | Control de velocidad (lineal/angular) |
| POST   | `/stop`      | Detener movimiento                    |
| GET    | `/status`    | Estado actual del movimiento          |
| POST   | `/forward`   | Mover hacia adelante                  |
| POST   | `/back`      | Mover hacia atrÃ¡s                     |
| POST   | `/left`      | Girar/mover a la izquierda            |
| POST   | `/right`     | Girar/mover a la derecha              |
| POST   | `/turnleft`  | Rotar hacia la izquierda              |
| POST   | `/turnright` | Rotar hacia la derecha                |

---

### 7.3. Endpoint `/move`

**Payload esperado:**

```json
{
  "linear": 0.3,
  "angular": 0.2,
  "duration_ms": 800
}
```

**Ejemplo `curl`:**

```bash
curl -X POST http://localhost:8000/move \
  -H "Content-Type: application/json" \
  -d '{"linear": 0.3, "angular": 0.2, "duration_ms": 800}'
```

---

## ğŸŒ WebSocket API

### Endpoint

```
ws://<host>:<port>/
```

Ejemplo local: `ws://localhost:8000/`

#### Suscripciones automÃ¡ticas (servidor â†’ cliente)

* `telemetry` â†’ telemetrÃ­a del robot
* `alert` â†’ alertas crÃ­ticas
* `mode` â†’ cambios de modo
* `ui_event` â†’ eventos de interfaz

Formato:

```json
{
  "topic": "telemetry",
  "data": { "battery": 92, "temp": 41.2 }
}
```

#### Comandos del cliente

1. **Movimiento (`motion_setpoint`)**

```json
{
  "type": "motion_setpoint",
  "x": 0, "y": 1, "z": 0, "speed": 40
}
```

2. **Publicar en bus**

```json
{
  "topic": "ui_event",
  "data": { "button": "start", "pressed": true }
}
```

Ejemplos listos en **JavaScript** y **Python** ya incluidos en el repo.

---

## ğŸ§ª Testing

Ejecutar pruebas unitarias:

```bash
pip install pytest
pytest
```

---

## ğŸ¤ ContribuciÃ³n

1. Haz un fork.
2. Crea una rama: `git checkout -b feature/nueva-funcion`
3. Commit: `git commit -m 'Agrega nueva funciÃ³n'`
4. Push: `git push origin feature/nueva-funcion`
5. Pull Request.

Estilo de cÃ³digo:

* Sigue [PEP8](https://peps.python.org/pep-0008/)
* Usa type hints
* Ejecuta `black` y `flake8` antes de commit

---

## ğŸ›£ï¸ Roadmap

* [ ] Mejorar performance en Jetson Nano
* [ ] Soporte para mÃºltiples cÃ¡maras
* [ ] DetecciÃ³n de objetos (YOLOv8)
* [ ] AutonomÃ­a bÃ¡sica con LiDAR

---

## ğŸ“œ Licencia

License Â© 2025 - HexaMind UH